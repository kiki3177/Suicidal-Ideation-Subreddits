{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4226,"status":"ok","timestamp":1740095853832,"user":{"displayName":"Ayesha Mahmood","userId":"05268202864701497016"},"user_tz":480},"id":"BRirHemhvgSp","outputId":"e12625e6-47e7-4a55-ba41-700ae5ef9648"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting fuzzywuzzy\n","  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n","Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n","Installing collected packages: fuzzywuzzy\n","Successfully installed fuzzywuzzy-0.18.0\n"]}],"source":["!pip install fuzzywuzzy"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6162,"status":"ok","timestamp":1740095862273,"user":{"displayName":"Ayesha Mahmood","userId":"05268202864701497016"},"user_tz":480},"id":"RJWH9ICzy3i1","outputId":"83be00ae-7b11-4e6a-eea2-55aa8852de34"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting rouge\n","  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from rouge) (1.17.0)\n","Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n","Installing collected packages: rouge\n","Successfully installed rouge-1.0.1\n"]}],"source":["!pip install rouge"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["This script takes human and LLM-generated (GPT-4) comments as responses to a submission and compares both the LLM and human comments for suicide and subreddit content. It performs string similarity comparisons using ROUGE-L, BLEU, and Fuzzy Similarity."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3156,"status":"ok","timestamp":1740095876772,"user":{"displayName":"Ayesha Mahmood","userId":"05268202864701497016"},"user_tz":480},"id":"TjWePnpmN9AV","outputId":"eb0690e6-f13e-467e-8e91-d9fd837e5d75"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n","  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n","/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]}],"source":["from csv import unregister_dialect\n","import pandas as pd\n","from fuzzywuzzy import fuzz\n","from rouge import Rouge\n","from nltk.translate.bleu_score import sentence_bleu\n","from google.colab import files\n","\n","\n","human_file_path = \"/content/2024_suicide_human_final_fixed.csv\"\n","llm_file_path = \"/content/2024_suicide_LLM_final_fixed.csv\"\n","output_file_name = \"2024_suicide_humanllmcomparison_results.csv\"\n","\n","human_data = pd.read_csv(human_file_path)\n","llm_data = pd.read_csv(llm_file_path)\n","\n","human_comments = human_data['content_comment'].astype(str).tolist()\n","llm_comments = llm_data['content_comment'].astype(str).tolist()\n","human_thread_ids = human_data['thread_id'].astype(str).tolist()\n","llm_thread_ids = llm_data['thread_id'].astype(str).tolist()\n","\n","\n","rouge = Rouge()\n","\n","# ROUGE-L scores\n","rouge_scores = [rouge.get_scores(llm, human, avg=True)['rouge-l'] for llm, human in zip(llm_comments, human_comments)]\n","\n","# BLEU scores\n","bleu_scores = [sentence_bleu([human.split()], llm.split()) for human, llm in zip(human_comments, llm_comments)]\n","\n","# FuzzyWuzzy similarity\n","fuzzy_scores = [fuzz.ratio(llm, human) for llm, human in zip(llm_comments, human_comments)]\n","\n","#  DataFrame for results\n","result_df = pd.DataFrame({\n","    \"human_thread_id\": human_thread_ids,  # Thread ID for human data\n","    \"human_comments\": human_comments,\n","    \"llm_thread_id\": llm_thread_ids,      # Thread ID for LLM data\n","    \"llm_comments\": llm_comments,\n","    \"rouge_l\": [score['f'] for score in rouge_scores],\n","    \"bleu_score\": bleu_scores,\n","    \"fuzzy_similarity\": fuzzy_scores,\n","})\n","\n","result_df.to_csv(f\"/content/{output_file_name}\", index=False)\n","\n","\n","\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMbH5wKbN7F8b3IH3fQafFM","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
