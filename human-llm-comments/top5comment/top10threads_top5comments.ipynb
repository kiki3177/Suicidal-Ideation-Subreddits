{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNYTxP9hd07uaFKD0Qc67aD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","\n","def process_multiple_csv_files(input_files, output_files):\n","    analyzer = SentimentIntensityAnalyzer()\n","\n","    for input_file, output_file in zip(input_files, output_files):\n","        print(f\"Processing file: {input_file}\")\n","\n","        try:\n","            # Loading the data, skipping bad lines\n","            df = pd.read_csv(\n","                input_file,\n","                on_bad_lines='skip',\n","                encoding='utf-8',\n","                encoding_errors='ignore'\n","            )\n","\n","            # Ensuring numeric types for scores\n","            df['score_submission'] = pd.to_numeric(df['score_submission'], errors='coerce')\n","            df['score_comment'] = pd.to_numeric(df['score_comment'], errors='coerce')\n","\n","            # Flitering threads with less than 5 comments\n","            valid_threads = df['thread_id'].value_counts()\n","            threads_with_5_or_more_comments = valid_threads[valid_threads >= 5].index\n","            filtered_df = df[df['thread_id'].isin(threads_with_5_or_more_comments)]\n","\n","            # Getting the top 10 threads by \"score_submission\"\n","            top_threads = (\n","                filtered_df[['thread_id', 'score_submission']]\n","                .drop_duplicates('thread_id')\n","                .nlargest(10, 'score_submission')\n","                .sort_values(by='score_submission', ascending=False)  # Sorting threads by score_submission\n","            )\n","\n","            top_thread_ids = top_threads['thread_id'].tolist()\n","\n","\n","            # Filtering rows to include only comments from the top 10 threads\n","            top_thread_comments = filtered_df[filtered_df['thread_id'].isin(top_thread_ids)]\n","            top_thread_comments['thread_id'] = pd.Categorical(\n","    top_thread_comments['thread_id'], categories=top_thread_ids, ordered=True\n",")\n","\n","\n","            # Getting the top 5 comments per thread by \"score_comment\"\n","            top_comments_per_thread = (\n","                top_thread_comments.sort_values(by=['thread_id', 'score_comment'], ascending=[True, False])\n","                .groupby('thread_id')\n","                .head(5)\n","\n","            )\n","            print(top_comments_per_thread)\n","\n","\n","            # Saving the result to a CSV file\n","            top_comments_per_thread.to_csv(output_file, index=False, encoding='utf-8', lineterminator='\\n')\n","            print(f\"Saved to {output_file}\")\n","        except Exception as e:\n","            print(f\"Error processing {input_file}: {e}\")\n","\n","\n","input_files = [\n","\n","    '/content/2020_depression_linked_llama_gemma_qwen.csv',\n","    '/content/2020_suicide_linked_llama_gemma_qwen.csv',\n","    '/content/2023_depression_linked_llama_gemma_qwen.csv',\n","    '/content/2023_suicide_linked_llama_gemma_qwen.csv',\n","    '/content/2024_depression_linked_llama_gemma_qwen.csv',\n","    '/content/2024_suicide_linked_llama_gemma_qwen.csv'\n","\n","\n","\n","\n","\n","]\n","output_files = [\n","    '2020_depression_human_output.csv',\n","    '2020_suicide_human_output.csv',\n","    '2023_depression_human_output.csv',\n","    '2023_suicide_human_output.csv',\n","    '2024_depression_human_output.csv',\n","    '2024_suicide_human_output.csv'\n","\n","]\n","\n","process_multiple_csv_files(input_files, output_files)"],"metadata":{"id":"OMgUoKJFGBHV"},"execution_count":null,"outputs":[]}]}